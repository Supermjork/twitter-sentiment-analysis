{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries to work with\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import torch\n",
    "import string\n",
    "import scipy as sci\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim as gns\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Version: 1.26.4\n",
      "Pandas Version: 2.2.3\n",
      "MatPlotLib Version: 3.9.2\n",
      "Seaborn Version: 0.13.2\n",
      "PyTorch Version: 2.5.1+cpu\n",
      "NLTK Version: 3.9.1\n",
      "SpaCy Version: 3.8.2\n",
      "Gensim Version: 4.3.3\n",
      "SciPy Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Display the libraries' versions used in this notebook\n",
    "version_list = {\"NumPy Version:\": np.__version__,\n",
    "                \"Pandas Version:\": pd.__version__,\n",
    "                \"MatPlotLib Version:\": mpl.__version__,\n",
    "                \"Seaborn Version:\": sns.__version__,\n",
    "                \"PyTorch Version:\": torch.__version__,\n",
    "                \"NLTK Version:\": nltk.__version__,\n",
    "                \"SpaCy Version:\": spacy.__version__,\n",
    "                \"Gensim Version:\": gns.__version__,\n",
    "                \"SciPy Version:\": sci.__version__}\n",
    "\n",
    "for (k, v) in version_list.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Exists\n",
      "Punctuation Data Exists\n",
      "Stopwords Package Exists\n",
      "Wordnet Package Exists\n"
     ]
    }
   ],
   "source": [
    "# Defining path to install NLTK libraries in\n",
    "NLTK_LIB_PATH = \".\\\\venv_nlp\\\\Lib\\\\nltk_data\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(NLTK_LIB_PATH)\n",
    "except FileExistsError:\n",
    "    print(\"Directory Exists.\")\n",
    "except:\n",
    "    print(\"Couldn't Make Directory.\")\n",
    "\n",
    "# Download extra parts of the library to use\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers\\\\punkt.zip\")                     # Punctuation\n",
    "    print(\"Punctuation Data Exists.\")\n",
    "except LookupError:\n",
    "    nltk.download('punkt', download_dir = NLTK_LIB_PATH)\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"corpora\\\\stopwords.zip\")                    # Stopwords\n",
    "    print(\"Stopwords Package Exists.\")\n",
    "except LookupError:\n",
    "    nltk.download('stopwords', download_dir = NLTK_LIB_PATH)\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"corpora\\\\wordnet.zip\")                      # Corpus\n",
    "    print(\"Wordnet Package Exists.\")\n",
    "except LookupError:\n",
    "    nltk.download('wordnet', download_dir = NLTK_LIB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies we've just loaded\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
