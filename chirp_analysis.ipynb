{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries to work with\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gensim as gns\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For the sake of Preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Word Embedding\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Version: 1.26.4\n",
      "Polars Version: 1.12.0\n",
      "MatPlotLib Version: 3.9.2\n",
      "Seaborn Version: 0.13.2\n",
      "PyTorch Version: 2.5.1+cpu\n",
      "NLTK Version: 3.9.1\n",
      "SpaCy Version: 3.8.2\n",
      "Gensim Version: 4.3.3\n",
      "SciPy Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Display the libraries' versions used in this notebook\n",
    "version_list = {\"NumPy Version:\": np.__version__,\n",
    "                \"Polars Version:\": pl.__version__,\n",
    "                \"MatPlotLib Version:\": mpl.__version__,\n",
    "                \"Seaborn Version:\": sns.__version__,\n",
    "                \"PyTorch Version:\": torch.__version__,\n",
    "                \"NLTK Version:\": nltk.__version__,\n",
    "                \"SpaCy Version:\": spacy.__version__,\n",
    "                \"Gensim Version:\": gns.__version__,\n",
    "                \"SciPy Version:\": sci.__version__}\n",
    "\n",
    "for (k, v) in version_list.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Exists.\n",
      "Punctuation Data Exists.\n",
      "Stopwords Package Exists.\n",
      "Wordnet Package Exists.\n"
     ]
    }
   ],
   "source": [
    "# Defining path to install NLTK libraries in\n",
    "NLTK_LIB_PATH = \".\\\\venv_nlp\\\\Lib\\\\nltk_data\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(NLTK_LIB_PATH)\n",
    "\n",
    "    print(\"Directory for NLTK Packages Created.. Installing (Hopefully)\")\n",
    "except FileExistsError:\n",
    "    print(\"Directory Exists.\")\n",
    "except:\n",
    "    print(\"Couldn't Make Directory.\")\n",
    "\n",
    "# Download extra parts of the library to use\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers\\\\punkt.zip\")                     # Punctuation\n",
    "    print(\"Punctuation Data Exists.\")\n",
    "except LookupError:\n",
    "    nltk.download('punkt', download_dir = NLTK_LIB_PATH)\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"corpora\\\\stopwords.zip\")                    # Stopwords\n",
    "    print(\"Stopwords Package Exists.\")\n",
    "except LookupError:\n",
    "    nltk.download('stopwords', download_dir = NLTK_LIB_PATH)\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"corpora\\\\wordnet.zip\")                      # Corpus\n",
    "    print(\"Wordnet Package Exists.\")\n",
    "except LookupError:\n",
    "    nltk.download('wordnet', download_dir = NLTK_LIB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "Importing our csv into our workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataframe\n",
    "text_data = pl.read_csv(\"datasets/twitter_training.csv\", has_header=False, new_columns = [\"tweet_id\", \"entity\", \"sentiment\", \"tweet_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>tweet_id</th><th>entity</th><th>sentiment</th><th>tweet_content</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;im getting on borderlands and …</td></tr><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;I am coming to the borders and…</td></tr><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;im getting on borderlands and …</td></tr><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;im coming on borderlands and i…</td></tr><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;im getting on borderlands 2 an…</td></tr><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;im getting into borderlands an…</td></tr><tr><td>2402</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;So I spent a few hours making …</td></tr><tr><td>2402</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;So I spent a couple of hours d…</td></tr><tr><td>2402</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;So I spent a few hours doing s…</td></tr><tr><td>2402</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;So I spent a few hours making …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌──────────┬─────────────┬───────────┬─────────────────────────────────┐\n",
       "│ tweet_id ┆ entity      ┆ sentiment ┆ tweet_content                   │\n",
       "│ ---      ┆ ---         ┆ ---       ┆ ---                             │\n",
       "│ i64      ┆ str         ┆ str       ┆ str                             │\n",
       "╞══════════╪═════════════╪═══════════╪═════════════════════════════════╡\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ im getting on borderlands and … │\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ I am coming to the borders and… │\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ im getting on borderlands and … │\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ im coming on borderlands and i… │\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ im getting on borderlands 2 an… │\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ im getting into borderlands an… │\n",
       "│ 2402     ┆ Borderlands ┆ Positive  ┆ So I spent a few hours making … │\n",
       "│ 2402     ┆ Borderlands ┆ Positive  ┆ So I spent a couple of hours d… │\n",
       "│ 2402     ┆ Borderlands ┆ Positive  ┆ So I spent a few hours doing s… │\n",
       "│ 2402     ┆ Borderlands ┆ Positive  ┆ So I spent a few hours making … │\n",
       "└──────────┴─────────────┴───────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing first 10 rows\n",
    "text_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>tweet_id</th><th>entity</th><th>sentiment</th><th>tweet_content</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>74682.0</td><td>&quot;74682&quot;</td><td>&quot;74682&quot;</td><td>&quot;73996&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;686&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>6432.586165</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>3740.42787</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>&quot;Amazon&quot;</td><td>&quot;Irrelevant&quot;</td><td>&quot; &quot;</td></tr><tr><td>&quot;25%&quot;</td><td>3195.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>6422.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>9601.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>13200.0</td><td>&quot;johnson&amp;johnson&quot;</td><td>&quot;Positive&quot;</td><td>&quot;🧻 at Home Depot on Hanley... I…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 5)\n",
       "┌────────────┬─────────────┬─────────────────┬────────────┬─────────────────────────────────┐\n",
       "│ statistic  ┆ tweet_id    ┆ entity          ┆ sentiment  ┆ tweet_content                   │\n",
       "│ ---        ┆ ---         ┆ ---             ┆ ---        ┆ ---                             │\n",
       "│ str        ┆ f64         ┆ str             ┆ str        ┆ str                             │\n",
       "╞════════════╪═════════════╪═════════════════╪════════════╪═════════════════════════════════╡\n",
       "│ count      ┆ 74682.0     ┆ 74682           ┆ 74682      ┆ 73996                           │\n",
       "│ null_count ┆ 0.0         ┆ 0               ┆ 0          ┆ 686                             │\n",
       "│ mean       ┆ 6432.586165 ┆ null            ┆ null       ┆ null                            │\n",
       "│ std        ┆ 3740.42787  ┆ null            ┆ null       ┆ null                            │\n",
       "│ min        ┆ 1.0         ┆ Amazon          ┆ Irrelevant ┆                                 │\n",
       "│ 25%        ┆ 3195.0      ┆ null            ┆ null       ┆ null                            │\n",
       "│ 50%        ┆ 6422.0      ┆ null            ┆ null       ┆ null                            │\n",
       "│ 75%        ┆ 9601.0      ┆ null            ┆ null       ┆ null                            │\n",
       "│ max        ┆ 13200.0     ┆ johnson&johnson ┆ Positive   ┆ 🧻 at Home Depot on Hanley...   │\n",
       "│            ┆             ┆                 ┆            ┆ I…                              │\n",
       "└────────────┴─────────────┴─────────────────┴────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for nulls\n",
    "text_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering our Null count within the tweet content column is practically $<1\\%$ (to be exact $0.927\\%$), we can safely drop those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = text_data.drop_nulls('tweet_content')\n",
    "text_data = text_data.drop('tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>entity</th><th>sentiment</th><th>tweet_content</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;73996&quot;</td><td>&quot;73996&quot;</td><td>&quot;73996&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>&quot;Amazon&quot;</td><td>&quot;Irrelevant&quot;</td><td>&quot; &quot;</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>&quot;johnson&amp;johnson&quot;</td><td>&quot;Positive&quot;</td><td>&quot;🧻 at Home Depot on Hanley... I…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 4)\n",
       "┌────────────┬─────────────────┬────────────┬─────────────────────────────────┐\n",
       "│ statistic  ┆ entity          ┆ sentiment  ┆ tweet_content                   │\n",
       "│ ---        ┆ ---             ┆ ---        ┆ ---                             │\n",
       "│ str        ┆ str             ┆ str        ┆ str                             │\n",
       "╞════════════╪═════════════════╪════════════╪═════════════════════════════════╡\n",
       "│ count      ┆ 73996           ┆ 73996      ┆ 73996                           │\n",
       "│ null_count ┆ 0               ┆ 0          ┆ 0                               │\n",
       "│ mean       ┆ null            ┆ null       ┆ null                            │\n",
       "│ std        ┆ null            ┆ null       ┆ null                            │\n",
       "│ min        ┆ Amazon          ┆ Irrelevant ┆                                 │\n",
       "│ 25%        ┆ null            ┆ null       ┆ null                            │\n",
       "│ 50%        ┆ null            ┆ null       ┆ null                            │\n",
       "│ 75%        ┆ null            ┆ null       ┆ null                            │\n",
       "│ max        ┆ johnson&johnson ┆ Positive   ┆ 🧻 at Home Depot on Hanley...   │\n",
       "│            ┆                 ┆            ┆ I…                              │\n",
       "└────────────┴─────────────────┴────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Preprocessing the text so it's somewhat cleaner than when obtianed, so that the model doesn't struggle (Instead, we will :D )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stopword set\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords.add(\"im\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a regex function to remove special characters, links, etc.\n",
    "def regex_cleanse(text: str):\n",
    "    text = re.sub(r'https\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'pic\\w+', '', text)\n",
    "    text = \" \".join([word for word in text.split() if word not in stopwords])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokeniser(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemma(tokens):\n",
    "    doc = model(tokens)\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a text preprocessing function to apply to all rows\n",
    "def preprocess_text(text: str) -> list[str]:\n",
    "    text = regex_cleanse(text.lower())\n",
    "    text = remove_emoji(text)\n",
    "    text = lemma(text)\n",
    "    #text = tokeniser(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chungus', 'bungus', 'ungus']\n"
     ]
    }
   ],
   "source": [
    "txt = preprocess_text(\"we chungus bungus ungus in this\")\n",
    "\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = text_data.with_columns(pl.col('tweet_content').map_elements(preprocess_text, return_dtype = list[str]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>entity</th><th>sentiment</th><th>tweet_content</th></tr><tr><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>[&quot;get&quot;, &quot;borderland&quot;, &quot;murder&quot;]</td></tr><tr><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>[&quot;come&quot;, &quot;border&quot;, &quot;kill&quot;]</td></tr><tr><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>[&quot;get&quot;, &quot;borderland&quot;, &quot;kill&quot;]</td></tr><tr><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>[&quot;come&quot;, &quot;borderland&quot;, &quot;murder&quot;]</td></tr><tr><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>[&quot;get&quot;, &quot;borderland&quot;, … &quot;murder&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────┬───────────┬─────────────────────────────────┐\n",
       "│ entity      ┆ sentiment ┆ tweet_content                   │\n",
       "│ ---         ┆ ---       ┆ ---                             │\n",
       "│ str         ┆ str       ┆ list[str]                       │\n",
       "╞═════════════╪═══════════╪═════════════════════════════════╡\n",
       "│ Borderlands ┆ Positive  ┆ [\"get\", \"borderland\", \"murder\"… │\n",
       "│ Borderlands ┆ Positive  ┆ [\"come\", \"border\", \"kill\"]      │\n",
       "│ Borderlands ┆ Positive  ┆ [\"get\", \"borderland\", \"kill\"]   │\n",
       "│ Borderlands ┆ Positive  ┆ [\"come\", \"borderland\", \"murder… │\n",
       "│ Borderlands ┆ Positive  ┆ [\"get\", \"borderland\", … \"murde… │\n",
       "└─────────────┴───────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>entity</th><th>sentiment</th><th>tweet_content</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;73996&quot;</td><td>&quot;73996&quot;</td><td>73996.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>&quot;Amazon&quot;</td><td>&quot;Irrelevant&quot;</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>&quot;johnson&amp;johnson&quot;</td><td>&quot;Positive&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 4)\n",
       "┌────────────┬─────────────────┬────────────┬───────────────┐\n",
       "│ statistic  ┆ entity          ┆ sentiment  ┆ tweet_content │\n",
       "│ ---        ┆ ---             ┆ ---        ┆ ---           │\n",
       "│ str        ┆ str             ┆ str        ┆ f64           │\n",
       "╞════════════╪═════════════════╪════════════╪═══════════════╡\n",
       "│ count      ┆ 73996           ┆ 73996      ┆ 73996.0       │\n",
       "│ null_count ┆ 0               ┆ 0          ┆ 0.0           │\n",
       "│ mean       ┆ null            ┆ null       ┆ null          │\n",
       "│ std        ┆ null            ┆ null       ┆ null          │\n",
       "│ min        ┆ Amazon          ┆ Irrelevant ┆ null          │\n",
       "│ 25%        ┆ null            ┆ null       ┆ null          │\n",
       "│ 50%        ┆ null            ┆ null       ┆ null          │\n",
       "│ 75%        ┆ null            ┆ null       ┆ null          │\n",
       "│ max        ┆ johnson&johnson ┆ Positive   ┆ null          │\n",
       "└────────────┴─────────────────┴────────────┴───────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['get', 'borderland', 'murder'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a series of vectors from every sentence\n",
    "model_ready_text = pd.Series(cleaned['tweet_content'])\n",
    "\n",
    "model_ready_text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec_cbow = Word2Vec(model_ready_text, min_count = 5, vector_size=100,  sg = 0, workers = 10,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
