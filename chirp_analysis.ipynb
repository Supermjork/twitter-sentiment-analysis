{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries to work with\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gensim as gns\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For the sake of Preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Word Embedding\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Version: 1.26.4\n",
      "Polars Version: 1.12.0\n",
      "MatPlotLib Version: 3.9.2\n",
      "Seaborn Version: 0.13.2\n",
      "PyTorch Version: 2.5.1+cpu\n",
      "NLTK Version: 3.9.1\n",
      "SpaCy Version: 3.8.2\n",
      "Gensim Version: 4.3.3\n",
      "SciPy Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Display the libraries' versions used in this notebook\n",
    "version_list = {\"NumPy Version:\": np.__version__,\n",
    "                \"Polars Version:\": pl.__version__,\n",
    "                \"MatPlotLib Version:\": mpl.__version__,\n",
    "                \"Seaborn Version:\": sns.__version__,\n",
    "                \"PyTorch Version:\": torch.__version__,\n",
    "                \"NLTK Version:\": nltk.__version__,\n",
    "                \"SpaCy Version:\": spacy.__version__,\n",
    "                \"Gensim Version:\": gns.__version__,\n",
    "                \"SciPy Version:\": sci.__version__}\n",
    "\n",
    "for (k, v) in version_list.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Exists.\n",
      "Punctuation Data Exists.\n",
      "Stopwords Package Exists.\n",
      "Wordnet Package Exists.\n"
     ]
    }
   ],
   "source": [
    "# Defining path to install NLTK libraries in\n",
    "NLTK_LIB_PATH = \".\\\\venv_nlp\\\\Lib\\\\nltk_data\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(NLTK_LIB_PATH)\n",
    "\n",
    "    print(\"Directory for NLTK Packages Created.. Installing (Hopefully)\")\n",
    "except FileExistsError:\n",
    "    print(\"Directory Exists.\")\n",
    "except:\n",
    "    print(\"Couldn't Make Directory.\")\n",
    "\n",
    "# Download extra parts of the library to use\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers\\\\punkt.zip\")                     # Punctuation\n",
    "    print(\"Punctuation Data Exists.\")\n",
    "except LookupError:\n",
    "    nltk.download('punkt', download_dir = NLTK_LIB_PATH)\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"corpora\\\\stopwords.zip\")                    # Stopwords\n",
    "    print(\"Stopwords Package Exists.\")\n",
    "except LookupError:\n",
    "    nltk.download('stopwords', download_dir = NLTK_LIB_PATH)\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"corpora\\\\wordnet.zip\")                      # Corpus\n",
    "    print(\"Wordnet Package Exists.\")\n",
    "except LookupError:\n",
    "    nltk.download('wordnet', download_dir = NLTK_LIB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "Importing our csv into our workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataframe\n",
    "text_data = pl.read_csv(\"datasets/twitter_training.csv\", has_header=False, new_columns = [\"tweet_id\", \"entity\", \"sentiment\", \"tweet_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>tweet_id</th><th>entity</th><th>sentiment</th><th>tweet_content</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;im getting on borderlands and …</td></tr><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;I am coming to the borders and…</td></tr><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;im getting on borderlands and …</td></tr><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;im coming on borderlands and i…</td></tr><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;im getting on borderlands 2 an…</td></tr><tr><td>2401</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;im getting into borderlands an…</td></tr><tr><td>2402</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;So I spent a few hours making …</td></tr><tr><td>2402</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;So I spent a couple of hours d…</td></tr><tr><td>2402</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;So I spent a few hours doing s…</td></tr><tr><td>2402</td><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>&quot;So I spent a few hours making …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌──────────┬─────────────┬───────────┬─────────────────────────────────┐\n",
       "│ tweet_id ┆ entity      ┆ sentiment ┆ tweet_content                   │\n",
       "│ ---      ┆ ---         ┆ ---       ┆ ---                             │\n",
       "│ i64      ┆ str         ┆ str       ┆ str                             │\n",
       "╞══════════╪═════════════╪═══════════╪═════════════════════════════════╡\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ im getting on borderlands and … │\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ I am coming to the borders and… │\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ im getting on borderlands and … │\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ im coming on borderlands and i… │\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ im getting on borderlands 2 an… │\n",
       "│ 2401     ┆ Borderlands ┆ Positive  ┆ im getting into borderlands an… │\n",
       "│ 2402     ┆ Borderlands ┆ Positive  ┆ So I spent a few hours making … │\n",
       "│ 2402     ┆ Borderlands ┆ Positive  ┆ So I spent a couple of hours d… │\n",
       "│ 2402     ┆ Borderlands ┆ Positive  ┆ So I spent a few hours doing s… │\n",
       "│ 2402     ┆ Borderlands ┆ Positive  ┆ So I spent a few hours making … │\n",
       "└──────────┴─────────────┴───────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing first 10 rows\n",
    "text_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>tweet_id</th><th>entity</th><th>sentiment</th><th>tweet_content</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>74682.0</td><td>&quot;74682&quot;</td><td>&quot;74682&quot;</td><td>&quot;73996&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;686&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>6432.586165</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>3740.42787</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>&quot;Amazon&quot;</td><td>&quot;Irrelevant&quot;</td><td>&quot; &quot;</td></tr><tr><td>&quot;25%&quot;</td><td>3195.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>6422.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>9601.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>13200.0</td><td>&quot;johnson&amp;johnson&quot;</td><td>&quot;Positive&quot;</td><td>&quot;🧻 at Home Depot on Hanley... I…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 5)\n",
       "┌────────────┬─────────────┬─────────────────┬────────────┬─────────────────────────────────┐\n",
       "│ statistic  ┆ tweet_id    ┆ entity          ┆ sentiment  ┆ tweet_content                   │\n",
       "│ ---        ┆ ---         ┆ ---             ┆ ---        ┆ ---                             │\n",
       "│ str        ┆ f64         ┆ str             ┆ str        ┆ str                             │\n",
       "╞════════════╪═════════════╪═════════════════╪════════════╪═════════════════════════════════╡\n",
       "│ count      ┆ 74682.0     ┆ 74682           ┆ 74682      ┆ 73996                           │\n",
       "│ null_count ┆ 0.0         ┆ 0               ┆ 0          ┆ 686                             │\n",
       "│ mean       ┆ 6432.586165 ┆ null            ┆ null       ┆ null                            │\n",
       "│ std        ┆ 3740.42787  ┆ null            ┆ null       ┆ null                            │\n",
       "│ min        ┆ 1.0         ┆ Amazon          ┆ Irrelevant ┆                                 │\n",
       "│ 25%        ┆ 3195.0      ┆ null            ┆ null       ┆ null                            │\n",
       "│ 50%        ┆ 6422.0      ┆ null            ┆ null       ┆ null                            │\n",
       "│ 75%        ┆ 9601.0      ┆ null            ┆ null       ┆ null                            │\n",
       "│ max        ┆ 13200.0     ┆ johnson&johnson ┆ Positive   ┆ 🧻 at Home Depot on Hanley...   │\n",
       "│            ┆             ┆                 ┆            ┆ I…                              │\n",
       "└────────────┴─────────────┴─────────────────┴────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for nulls\n",
    "text_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering our Null count within the tweet content column is practically $<1\\%$ (to be exact $0.927\\%$), we can safely drop those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = text_data.drop_nulls('tweet_content')\n",
    "text_data = text_data.drop('tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>entity</th><th>sentiment</th><th>tweet_content</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;73996&quot;</td><td>&quot;73996&quot;</td><td>&quot;73996&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>&quot;Amazon&quot;</td><td>&quot;Irrelevant&quot;</td><td>&quot; &quot;</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>&quot;johnson&amp;johnson&quot;</td><td>&quot;Positive&quot;</td><td>&quot;🧻 at Home Depot on Hanley... I…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 4)\n",
       "┌────────────┬─────────────────┬────────────┬─────────────────────────────────┐\n",
       "│ statistic  ┆ entity          ┆ sentiment  ┆ tweet_content                   │\n",
       "│ ---        ┆ ---             ┆ ---        ┆ ---                             │\n",
       "│ str        ┆ str             ┆ str        ┆ str                             │\n",
       "╞════════════╪═════════════════╪════════════╪═════════════════════════════════╡\n",
       "│ count      ┆ 73996           ┆ 73996      ┆ 73996                           │\n",
       "│ null_count ┆ 0               ┆ 0          ┆ 0                               │\n",
       "│ mean       ┆ null            ┆ null       ┆ null                            │\n",
       "│ std        ┆ null            ┆ null       ┆ null                            │\n",
       "│ min        ┆ Amazon          ┆ Irrelevant ┆                                 │\n",
       "│ 25%        ┆ null            ┆ null       ┆ null                            │\n",
       "│ 50%        ┆ null            ┆ null       ┆ null                            │\n",
       "│ 75%        ┆ null            ┆ null       ┆ null                            │\n",
       "│ max        ┆ johnson&johnson ┆ Positive   ┆ 🧻 at Home Depot on Hanley...   │\n",
       "│            ┆                 ┆            ┆ I…                              │\n",
       "└────────────┴─────────────────┴────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Preprocessing the text so it's somewhat cleaner than when obtianed, so that the model doesn't struggle (Instead, we will :D )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stopword set\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords.add(\"im\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a regex function to remove special characters, links, etc.\n",
    "def regex_cleanse(text: str):\n",
    "    text = re.sub(r'https\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'pic\\w+', '', text)\n",
    "    text = \" \".join([word for word in text.split() if word not in stopwords])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokeniser(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemma(tokens):\n",
    "    doc = model(tokens)\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a text preprocessing function to apply to all rows\n",
    "def preprocess_text(text: str) -> list[str]:\n",
    "    text = regex_cleanse(text.lower())\n",
    "    text = remove_emoji(text)\n",
    "    text = lemma(text)\n",
    "    #text = tokeniser(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chungus', 'bungus', 'ungus']\n"
     ]
    }
   ],
   "source": [
    "txt = preprocess_text(\"we chungus bungus ungus in this\")\n",
    "\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = text_data.with_columns(pl.col('tweet_content').map_elements(preprocess_text, return_dtype = list[str]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>entity</th><th>sentiment</th><th>tweet_content</th></tr><tr><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>[&quot;get&quot;, &quot;borderland&quot;, &quot;murder&quot;]</td></tr><tr><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>[&quot;come&quot;, &quot;border&quot;, &quot;kill&quot;]</td></tr><tr><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>[&quot;get&quot;, &quot;borderland&quot;, &quot;kill&quot;]</td></tr><tr><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>[&quot;come&quot;, &quot;borderland&quot;, &quot;murder&quot;]</td></tr><tr><td>&quot;Borderlands&quot;</td><td>&quot;Positive&quot;</td><td>[&quot;get&quot;, &quot;borderland&quot;, … &quot;murder&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────┬───────────┬─────────────────────────────────┐\n",
       "│ entity      ┆ sentiment ┆ tweet_content                   │\n",
       "│ ---         ┆ ---       ┆ ---                             │\n",
       "│ str         ┆ str       ┆ list[str]                       │\n",
       "╞═════════════╪═══════════╪═════════════════════════════════╡\n",
       "│ Borderlands ┆ Positive  ┆ [\"get\", \"borderland\", \"murder\"… │\n",
       "│ Borderlands ┆ Positive  ┆ [\"come\", \"border\", \"kill\"]      │\n",
       "│ Borderlands ┆ Positive  ┆ [\"get\", \"borderland\", \"kill\"]   │\n",
       "│ Borderlands ┆ Positive  ┆ [\"come\", \"borderland\", \"murder… │\n",
       "│ Borderlands ┆ Positive  ┆ [\"get\", \"borderland\", … \"murde… │\n",
       "└─────────────┴───────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>entity</th><th>sentiment</th><th>tweet_content</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;73996&quot;</td><td>&quot;73996&quot;</td><td>73996.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>&quot;Amazon&quot;</td><td>&quot;Irrelevant&quot;</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>&quot;johnson&amp;johnson&quot;</td><td>&quot;Positive&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 4)\n",
       "┌────────────┬─────────────────┬────────────┬───────────────┐\n",
       "│ statistic  ┆ entity          ┆ sentiment  ┆ tweet_content │\n",
       "│ ---        ┆ ---             ┆ ---        ┆ ---           │\n",
       "│ str        ┆ str             ┆ str        ┆ f64           │\n",
       "╞════════════╪═════════════════╪════════════╪═══════════════╡\n",
       "│ count      ┆ 73996           ┆ 73996      ┆ 73996.0       │\n",
       "│ null_count ┆ 0               ┆ 0          ┆ 0.0           │\n",
       "│ mean       ┆ null            ┆ null       ┆ null          │\n",
       "│ std        ┆ null            ┆ null       ┆ null          │\n",
       "│ min        ┆ Amazon          ┆ Irrelevant ┆ null          │\n",
       "│ 25%        ┆ null            ┆ null       ┆ null          │\n",
       "│ 50%        ┆ null            ┆ null       ┆ null          │\n",
       "│ 75%        ┆ null            ┆ null       ┆ null          │\n",
       "│ max        ┆ johnson&johnson ┆ Positive   ┆ null          │\n",
       "└────────────┴─────────────────┴────────────┴───────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get', 'borderland', 'murder']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a series of vectors from every sentence\n",
    "model_ready_text = cleaned['tweet_content'].to_list()\n",
    "\n",
    "model_ready_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_cbow = Word2Vec(model_ready_text, min_count = 5, vector_size=100,  sg = 0, workers = 10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.38710666e-01,  7.39726305e-01,  6.61083534e-02,  9.77369606e-01,\n",
       "        9.96545702e-02,  5.15600443e-01,  1.37819541e+00, -9.09821391e-02,\n",
       "       -1.66094720e+00, -1.03679037e+00,  6.54140264e-02, -7.50853598e-01,\n",
       "       -9.22983348e-01, -2.31775641e-02, -6.88205183e-01, -1.31816622e-02,\n",
       "        1.70911455e+00, -4.06895757e-01,  3.09767067e-01,  5.42064190e-01,\n",
       "        7.13509619e-01, -4.74175304e-01,  4.48252857e-02,  1.29425216e+00,\n",
       "       -7.17418909e-01,  6.14135563e-01, -1.75333932e-01, -1.42536151e+00,\n",
       "        2.20917404e-01, -9.72289324e-01, -5.76742113e-01,  4.19251382e-01,\n",
       "        7.89716287e-05, -4.14689034e-01,  2.23332429e+00,  2.06944799e+00,\n",
       "        4.34534520e-01,  7.12677717e-01, -1.13264954e+00, -2.44789794e-01,\n",
       "       -1.45503968e-01, -1.15199745e+00, -1.95202899e+00,  1.17559755e+00,\n",
       "       -1.02075088e+00, -7.86058009e-02,  1.25684333e+00, -5.90531349e-01,\n",
       "       -8.50952923e-01, -1.66625902e-02,  4.12924260e-01,  2.62208152e+00,\n",
       "       -9.39794540e-01,  9.27228391e-01, -7.85121381e-01,  4.24949646e-01,\n",
       "        1.41669452e+00,  5.25522172e-01, -2.76501513e+00,  6.04113825e-02,\n",
       "        1.14560135e-01,  3.48559588e-01, -9.91039634e-01,  1.36841202e+00,\n",
       "        6.23531163e-01, -1.50170967e-01, -4.60139066e-01, -4.02622312e-01,\n",
       "        2.33176023e-01, -7.72503838e-02,  1.56503677e-01,  5.00597477e-01,\n",
       "        1.45453882e+00, -1.53003074e-02,  2.22683996e-01,  2.27444124e+00,\n",
       "       -1.18192208e+00,  1.59335947e+00,  5.41793644e-01,  4.08787966e-01,\n",
       "       -1.12355852e+00,  5.31904042e-01, -2.50754319e-02, -5.57485342e-01,\n",
       "        8.55610669e-02,  7.02543616e-01,  5.00722647e-01,  1.62737370e+00,\n",
       "        1.26632667e+00,  1.16908419e+00,  1.45895612e+00, -8.55826139e-01,\n",
       "        6.17379010e-01,  1.46694040e+00,  1.03651561e-01,  2.08671308e+00,\n",
       "       -1.46802795e+00,  1.06552100e+00, -3.12309444e-01, -4.60953712e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_cbow.wv['nvidia']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
